{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 06. Baseline Comparison: PyTorch MLP\n",
                "\n",
                "To evaluate the performance of the **Triglial Reservoir** (which achieved ~71% accuracy on 500 samples), we compare it against a traditional **Multi-Layer Perceptron (MLP)** trained on the exact same data.\n",
                "\n",
                "## Model Architecture\n",
                "- **Input**: 784 (28x28 pixels)\n",
                "- **Hidden**: 100 (ReLU activation) - Same size as the reservoir\n",
                "- **Output**: 10 (LogSoftmax)\n",
                "- **Optimizer**: Adam\n",
                "- **Loss**: CrossEntropyLoss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data (Same Subset)\n",
                "We use the same subset size (500 training samples) to ensure a fair comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
                "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
                "\n",
                "subset_size = 500\n",
                "train_subset = Subset(train_data, range(subset_size))\n",
                "test_subset = Subset(test_data, range(100))\n",
                "\n",
                "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
                "test_loader = DataLoader(test_subset, batch_size=100, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define MLP Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleMLP(nn.Module):\n",
                "    def __init__(self, input_dim=784, hidden_dim=100, output_dim=10):\n",
                "        super(SimpleMLP, self).__init__()\n",
                "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = x.view(-1, 784) # Flatten\n",
                "        x = self.fc1(x)\n",
                "        x = self.relu(x)\n",
                "        x = self.fc2(x)\n",
                "        return x\n",
                "\n",
                "model = SimpleMLP()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "criterion = nn.CrossEntropyLoss()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 20\n",
                "losses = []\n",
                "\n",
                "print(f\"Training MLP on {subset_size} samples for {epochs} epochs...\")\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for data, target in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        output = model(data)\n",
                "        loss = criterion(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    losses.append(epoch_loss / len(train_loader))\n",
                "    if (epoch + 1) % 5 == 0:\n",
                "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {losses[-1]:.4f}\")\n",
                "\n",
                "plt.plot(losses)\n",
                "plt.title(\"Training Loss\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "correct = 0\n",
                "total = 0\n",
                "\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        output = model(data)\n",
                "        pred = output.argmax(dim=1, keepdim=True)\n",
                "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
                "        total += target.size(0)\n",
                "\n",
                "accuracy = correct / total\n",
                "print(f\"Baseline MLP Accuracy: {accuracy * 100:.2f}%\")\n",
                "print(f\"Triglial Reservoir Accuracy: ~71.00% (Reference)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}