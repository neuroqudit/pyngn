{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05. Benchmark & Comparison: Triglial Reservoir vs. MLP\n",
                "\n",
                "This notebook benchmarks the **Triglial Reservoir** (3GSNN) on the MNIST digit classification task and compares it against a traditional **Multi-Layer Perceptron (MLP)** baseline.\n",
                "\n",
                "## Models\n",
                "1.  **Triglial Reservoir (3GSNN)**:\n",
                "    - **Encoder**: Poisson coding (Pixels -> Spikes).\n",
                "    - **Reservoir**: Neurons + Astrocytes + Microglia + Delays.\n",
                "    - **Readout**: Ridge Regression (Closed-form solution).\n",
                "2.  **Baseline MLP**:\n",
                "    - **Architecture**: Input -> Hidden (ReLU) -> Output (LogSoftmax).\n",
                "    - **Training**: Backpropagation (Adam Optimizer).\n",
                "\n",
                "Both models use the exact same data subset for a fair comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "\n",
                "from pyngn.reservoir import TriglialReservoir\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "We use a subset of MNIST (e.g., 500 samples) to demonstrate performance on limited data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "# Download MNIST\n",
                "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
                "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
                "\n",
                "# Use subset for quick benchmark\n",
                "subset_size = 500\n",
                "train_subset = Subset(train_data, range(subset_size))\n",
                "test_subset = Subset(test_data, range(100))\n",
                "\n",
                "# DataLoaders\n",
                "# Reservoir processes 1 sample at a time (or small batches if supported)\n",
                "train_loader_res = DataLoader(train_subset, batch_size=1, shuffle=True)\n",
                "test_loader_res = DataLoader(test_subset, batch_size=1, shuffle=False)\n",
                "\n",
                "# MLP processes batches\n",
                "train_loader_mlp = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
                "test_loader_mlp = DataLoader(test_subset, batch_size=100, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Part 1: Triglial Reservoir (3GSNN)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def poisson_encode(image, time_steps=50, gain=10.0):\n",
                "    pixels = image.view(-1)\n",
                "    rate = pixels * gain\n",
                "    prob = torch.clamp(rate * 0.1, 0, 1)\n",
                "    spikes = torch.rand(time_steps, pixels.shape[0]) < prob.unsqueeze(0)\n",
                "    return spikes.float()\n",
                "\n",
                "input_dim = 784\n",
                "hidden_dim = 100\n",
                "output_dim = 10\n",
                "\n",
                "reservoir_model = TriglialReservoir(input_dim, hidden_dim, output_dim, \n",
                "                                    dt=1.0, max_delay=10,\n",
                "                                    astro_params={'target_rate': 0.1},\n",
                "                                    micro_params={'pruning_threshold': 0.3})\n",
                "\n",
                "print(\"Triglial Reservoir Initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Train Reservoir Readout"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_states = []\n",
                "Y_train_targets = []\n",
                "\n",
                "print(\"Collecting reservoir states...\")\n",
                "for i, (img, label) in enumerate(train_loader_res):\n",
                "    spikes = poisson_encode(img)\n",
                "    \n",
                "    # Run Reservoir & Get State\n",
                "    prediction, state = reservoir_model(spikes, return_state=True)\n",
                "    \n",
                "    X_train_states.append(state.squeeze(0))\n",
                "    \n",
                "    target = torch.zeros(10)\n",
                "    target[label] = 1.0\n",
                "    Y_train_targets.append(target)\n",
                "    \n",
                "    if (i + 1) % 100 == 0:\n",
                "        print(f\"Processed {i + 1} samples\")\n",
                "\n",
                "X_train = torch.stack(X_train_states)\n",
                "Y_train = torch.stack(Y_train_targets)\n",
                "\n",
                "print(f\"Training Readout on {X_train.shape[0]} samples...\")\n",
                "reservoir_model.readout.fit(X_train, Y_train)\n",
                "print(\"Reservoir Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Evaluate Reservoir"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res_correct = 0\n",
                "res_total = 0\n",
                "\n",
                "print(\"Evaluating Reservoir...\")\n",
                "with torch.no_grad():\n",
                "    for img, label in test_loader_res:\n",
                "        spikes = poisson_encode(img)\n",
                "        prediction = reservoir_model(spikes)\n",
                "        \n",
                "        predicted_class = torch.argmax(prediction).item()\n",
                "        if predicted_class == label.item():\n",
                "            res_correct += 1\n",
                "        res_total += 1\n",
                "\n",
                "res_accuracy = res_correct / res_total\n",
                "print(f\"Triglial Reservoir Accuracy: {res_accuracy * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Part 2: Baseline MLP (PyTorch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleMLP(nn.Module):\n",
                "    def __init__(self, input_dim=784, hidden_dim=100, output_dim=10):\n",
                "        super(SimpleMLP, self).__init__()\n",
                "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = x.view(-1, 784)\n",
                "        x = self.fc1(x)\n",
                "        x = self.relu(x)\n",
                "        x = self.fc2(x)\n",
                "        return x\n",
                "\n",
                "mlp_model = SimpleMLP(hidden_dim=hidden_dim)\n",
                "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "print(\"MLP Initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Train MLP"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 20\n",
                "losses = []\n",
                "\n",
                "print(f\"Training MLP on {subset_size} samples for {epochs} epochs...\")\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    mlp_model.train()\n",
                "    epoch_loss = 0\n",
                "    for data, target in train_loader_mlp:\n",
                "        optimizer.zero_grad()\n",
                "        output = mlp_model(data)\n",
                "        loss = criterion(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    losses.append(epoch_loss / len(train_loader_mlp))\n",
                "    if (epoch + 1) % 5 == 0:\n",
                "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {losses[-1]:.4f}\")\n",
                "\n",
                "plt.plot(losses)\n",
                "plt.title(\"MLP Training Loss\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Evaluate MLP"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlp_model.eval()\n",
                "mlp_correct = 0\n",
                "mlp_total = 0\n",
                "\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader_mlp:\n",
                "        output = mlp_model(data)\n",
                "        pred = output.argmax(dim=1, keepdim=True)\n",
                "        mlp_correct += pred.eq(target.view_as(pred)).sum().item()\n",
                "        mlp_total += target.size(0)\n",
                "\n",
                "mlp_accuracy = mlp_correct / mlp_total\n",
                "print(f\"Baseline MLP Accuracy: {mlp_accuracy * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Comparison Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = ['Triglial Reservoir', 'Baseline MLP']\n",
                "accuracies = [res_accuracy * 100, mlp_accuracy * 100]\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "bars = plt.bar(labels, accuracies, color=['#4CAF50', '#2196F3'])\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.title('Model Comparison (MNIST Subset)')\n",
                "plt.ylim(0, 100)\n",
                "\n",
                "for bar in bars:\n",
                "    height = bar.get_height()\n",
                "    plt.text(bar.get_x() + bar.get_width()/2., height, \n",
                "             f'{height:.2f}%', \n",
                "             ha='center', va='bottom')\n",
                "\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
