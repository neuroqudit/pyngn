{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05. Benchmark: MNIST Classification\n",
                "\n",
                "This notebook benchmarks the **Triglial Reservoir** (3GSNN) on the MNIST digit classification task.\n",
                "We use a Liquid State Machine (LSM) approach:\n",
                "1.  **Encoder**: Convert image pixels to spike trains (Poisson coding).\n",
                "2.  **Reservoir**: TriglialReservoir (Neurons + Astrocytes + Microglia + Delays) processes the spatiotemporal patterns.\n",
                "3.  **Readout**: Ridge Regression trains on the reservoir states to predict the digit class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "\n",
                "from pyngn.reservoir import TriglialReservoir\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "We use a subset of MNIST for speed in this demo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "# Download MNIST\n",
                "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
                "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
                "\n",
                "# Use subset for quick benchmark (e.g., 500 samples)\n",
                "subset_size = 500\n",
                "train_subset = Subset(train_data, range(subset_size))\n",
                "test_subset = Subset(test_data, range(100))\n",
                "\n",
                "train_loader = DataLoader(train_subset, batch_size=1, shuffle=True)\n",
                "test_loader = DataLoader(test_subset, batch_size=1, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Poisson Encoder\n",
                "Convert pixel intensity (0-1) to spike probability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def poisson_encode(image, time_steps=50, gain=10.0):\n",
                "    # image: [1, 28, 28]\n",
                "    # Flatten: [784]\n",
                "    pixels = image.view(-1)\n",
                "    \n",
                "    # Rate proportional to intensity\n",
                "    rate = pixels * gain # Hz (approx)\n",
                "    \n",
                "    # Generate spikes: [time_steps, 784]\n",
                "    # Prob of spike per step (dt=1ms) = rate * dt/1000\n",
                "    # Let's assume rate is prob per step for simplicity\n",
                "    prob = torch.clamp(rate * 0.1, 0, 1) # Scaling factor\n",
                "    \n",
                "    spikes = torch.rand(time_steps, pixels.shape[0]) < prob.unsqueeze(0)\n",
                "    return spikes.float()\n",
                "\n",
                "# Visualize one sample\n",
                "img, label = train_subset[0]\n",
                "spikes = poisson_encode(img)\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.imshow(spikes.T, aspect='auto', cmap='Greys')\n",
                "plt.title(f\"Spike Train for Digit {label}\")\n",
                "plt.xlabel(\"Time\")\n",
                "plt.ylabel(\"Input Neuron\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Initialize Reservoir"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_dim = 784\n",
                "hidden_dim = 100 # Small reservoir for demo\n",
                "output_dim = 10  # Digits 0-9\n",
                "\n",
                "model = TriglialReservoir(input_dim, hidden_dim, output_dim, \n",
                "                          dt=1.0, max_delay=10,\n",
                "                          astro_params={'target_rate': 0.1},\n",
                "                          micro_params={'pruning_threshold': 0.3})\n",
                "\n",
                "print(\"Reservoir Initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training (Readout)\n",
                "We run the reservoir on training data, collect states, and train the readout."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_states = []\n",
                "Y_train_targets = []\n",
                "\n",
                "print(\"Collecting reservoir states...\")\n",
                "for i, (img, label) in enumerate(train_loader):\n",
                "    # Encode\n",
                "    spikes = poisson_encode(img)\n",
                "    \n",
                "    # Run Reservoir\n",
                "    # Collect state for batch training\n",
                "    prediction, state = model(spikes, return_state=True)\n",
                "    \n",
                "    X_train_states.append(state.squeeze(0)) # [hidden_dim]\n",
                "    \n",
                "    # One-hot target\n",
                "    target = torch.zeros(10)\n",
                "    target[label] = 1.0\n",
                "    Y_train_targets.append(target)\n",
                "    \n",
                "    if (i + 1) % 100 == 0:\n",
                "        print(f\"Processed {i + 1} samples\")\n",
                "\n",
                "# Stack\n",
                "X_train = torch.stack(X_train_states) # [n_samples, hidden_dim]\n",
                "Y_train = torch.stack(Y_train_targets) # [n_samples, output_dim]\n",
                "\n",
                "print(f\"Training Readout on {X_train.shape[0]} samples...\")\n",
                "model.readout.fit(X_train, Y_train)\n",
                "print(\"Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation\n",
                "Test on unseen data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "correct = 0\n",
                "total = 0\n",
                "\n",
                "print(\"Evaluating...\")\n",
                "with torch.no_grad():\n",
                "    for img, label in test_loader:\n",
                "        spikes = poisson_encode(img)\n",
                "        \n",
                "        # Run Reservoir (no training)\n",
                "        prediction = model(spikes)\n",
                "        \n",
                "        predicted_class = torch.argmax(prediction).item()\n",
                "        true_class = label.item()\n",
                "        \n",
                "        if predicted_class == true_class:\n",
                "            correct += 1\n",
                "        total += 1\n",
                "\n",
                "accuracy = correct / total\n",
                "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}