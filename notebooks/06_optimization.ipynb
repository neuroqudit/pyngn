{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 06. Performance Optimization: Hyperparameter Search\n",
                "\n",
                "This notebook performs a **Grid Search** to optimize the hyperparameters of the **Triglial Reservoir** (3GSNN) for MNIST classification.\n",
                "\n",
                "## Parameters to Tune\n",
                "1.  **Reservoir Size (`hidden_dim`)**: 100 vs 200 (Larger is usually better but slower).\n",
                "2.  **Spectral Radius**: Scales the recurrent weights. Controls the dynamic regime (stable vs. chaotic).\n",
                "3.  **Microglia Pruning Threshold**: Controls sparsity.\n",
                "4.  **Astrocyte Target Rate**: Controls homeostatic activity levels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "import itertools\n",
                "import time\n",
                "\n",
                "from pyngn.reservoir import TriglialReservoir\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data (Subset)\n",
                "Using a small subset (500 samples) for faster search."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
                "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
                "\n",
                "subset_size = 500\n",
                "train_subset = Subset(train_data, range(subset_size))\n",
                "test_subset = Subset(test_data, range(100))\n",
                "\n",
                "train_loader = DataLoader(train_subset, batch_size=1, shuffle=True)\n",
                "test_loader = DataLoader(test_subset, batch_size=1, shuffle=False)\n",
                "\n",
                "def poisson_encode(image, time_steps=50, gain=10.0):\n",
                "    pixels = image.view(-1)\n",
                "    rate = pixels * gain\n",
                "    prob = torch.clamp(rate * 0.1, 0, 1)\n",
                "    spikes = torch.rand(time_steps, pixels.shape[0]) < prob.unsqueeze(0)\n",
                "    return spikes.float()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Evaluation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(hidden_dim, spectral_radius, pruning_threshold, target_rate):\n",
                "    # Initialize Model\n",
                "    model = TriglialReservoir(784, hidden_dim, 10, \n",
                "                              dt=1.0, max_delay=10,\n",
                "                              astro_params={'target_rate': target_rate},\n",
                "                              micro_params={'pruning_threshold': pruning_threshold})\n",
                "    \n",
                "    # Scale Recurrent Weights (Spectral Radius)\n",
                "    # Note: This is a simplified scaling. Proper spectral radius requires eigen-decomposition.\n",
                "    # Here we just scale the std dev of initialization.\n",
                "    with torch.no_grad():\n",
                "        model.recurrent_weights *= spectral_radius\n",
                "    \n",
                "    # Train Readout\n",
                "    X_train_states = []\n",
                "    Y_train_targets = []\n",
                "    \n",
                "    for img, label in train_loader:\n",
                "        spikes = poisson_encode(img)\n",
                "        _, state = model(spikes, return_state=True)\n",
                "        X_train_states.append(state.squeeze(0))\n",
                "        target = torch.zeros(10)\n",
                "        target[label] = 1.0\n",
                "        Y_train_targets.append(target)\n",
                "        \n",
                "    X_train = torch.stack(X_train_states)\n",
                "    Y_train = torch.stack(Y_train_targets)\n",
                "    model.readout.fit(X_train, Y_train)\n",
                "    \n",
                "    # Test\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    with torch.no_grad():\n",
                "        for img, label in test_loader:\n",
                "            spikes = poisson_encode(img)\n",
                "            prediction = model(spikes)\n",
                "            if torch.argmax(prediction).item() == label.item():\n",
                "                correct += 1\n",
                "            total += 1\n",
                "            \n",
                "    return correct / total"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Grid Search Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parameter Grid\n",
                "param_grid = {\n",
                "    'hidden_dim': [100, 200],\n",
                "    'spectral_radius': [1.0, 1.5], # Scaling factor\n",
                "    'pruning_threshold': [0.1, 0.3, 0.5],\n",
                "    'target_rate': [0.05, 0.1]\n",
                "}\n",
                "\n",
                "results = []\n",
                "best_acc = 0.0\n",
                "best_params = {}\n",
                "\n",
                "keys = param_grid.keys()\n",
                "combinations = list(itertools.product(*param_grid.values()))\n",
                "\n",
                "print(f\"Starting Grid Search with {len(combinations)} combinations...\")\n",
                "start_time = time.time()\n",
                "\n",
                "for i, values in enumerate(combinations):\n",
                "    params = dict(zip(keys, values))\n",
                "    print(f\"Testing {params}...\")\n",
                "    \n",
                "    acc = evaluate_model(**params)\n",
                "    results.append({'params': params, 'accuracy': acc})\n",
                "    \n",
                "    print(f\"  -> Accuracy: {acc*100:.2f}%\")\n",
                "    \n",
                "    if acc > best_acc:\n",
                "        best_acc = acc\n",
                "        best_params = params\n",
                "\n",
                "elapsed = time.time() - start_time\n",
                "print(f\"\\nSearch Complete in {elapsed:.2f}s\")\n",
                "print(f\"Best Accuracy: {best_acc*100:.2f}%\")\n",
                "print(f\"Best Parameters: {best_params}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple visualization of accuracy distribution\n",
                "accuracies = [r['accuracy'] for r in results]\n",
                "plt.hist(accuracies, bins=10)\n",
                "plt.title(\"Accuracy Distribution from Grid Search\")\n",
                "plt.xlabel(\"Accuracy\")\n",
                "plt.ylabel(\"Count\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}